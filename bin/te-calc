#!/usr/bin/env python
# -*- python -*-
import numpy as np
import tuningerrors as terr
import apprentice as app

def mkSignal(IO, p):
    return [r.predict(p) for r in IO._RA]

def plotEigenTuneHistos(IO, jd, xmids, central, ETs, plot_prefix=""):

    TUNED = np.array(mkSignal(IO, central))
    ETD=[]
    for i in range(int(len(ETs)/2)):
        ETD.append([np.array(mkSignal(IO, ETs[i*2])), np.array(mkSignal(IO, ETs[i*2+1]))])

    # dfp = []
    # for num, y in enumerate(TUNED):
        # a = max(map(abs, [ETD[0][0][num]-y, ETD[0][1][num]-y]))
        # b = max(map(abs, [ETD[1][0][num]-y, ETD[1][1][num]-y]))
        # dfp.append(np.sqrt(a**2+b**2))

    # dfm = []
    # for num, y in enumerate(TUNED):
        # a = max(map(abs, [y-ETD[0][0][num], y-ETD[0][1][num]]))
        # b = max(map(abs, [y-ETD[1][0][num], y-ETD[1][1][num]]))
        # dfm.append(np.sqrt(a**2+b**2))

    # DFP=TUNED+dfp
    # DFM=TUNED-dfm

    # ERR = np.sqrt(1./np.array(jd["TUNEINVDATACOV"]).reshape((jd["NBINS"],jd["NBINS"])).diagonal())
    ERR = IO._E
    YV  = jd["YVALS"]

    from matplotlib import pyplot as plt
    import matplotlib as mpl
    plt.style.use('ggplot')
    plt.figure(figsize=(10,8))
    #
    X = np.array(range(len(YV)))+0.5
    # plt.fill_between(X, DFP, DFM, alpha=0.5, color="red")
    # plt.yscale("log")
    plt.xlabel("# Bin")
    plt.ylabel("Entries")

    etcols=["b", "m", "c"]
    for num, ET in enumerate(ETD):
        try:
            plt.plot(X, ET[0], "%s-"%etcols[num], linewidth=3, label="ET%i+"%(num+1))
            plt.plot(X, ET[1], "%s--"%etcols[num], linewidth=3, label="ET%i-"%(num+1))
        except:
            print(num)
            print(ET)
            pass

    plt.errorbar(X, YV, yerr=ERR, marker="o", linestyle="none", color="k", label="'Data'")
    plt.plot(X, TUNED, "r-", linewidth=3, label="Central tune ($\chi^2=%.1f$)"%jd["TUNECHI2"])
    plt.legend()
    # plt.ylim((100, 580))
    #
    plt.savefig("result-%s-%i-%s.pdf"%(plot_prefix, jd["NBINS"], jd["CORRMODE"]))



def chi2wCov(DV, R, InvCov, x):
    import pyrapp
    if type(R[0]) == pyrapp.rapp.Rapp:
        I = [r(x) for r in R]
    else:
        I = mkSignal2d(x, R) # R is xmids here
    diff = DV - np.array(I)
    return sum(diff*InvCov.diagonal()*(diff))

if __name__ == "__main__":

    import optparse, os, sys
    op = optparse.OptionParser(usage=__doc__)
    op.add_option("-v", "--debug", dest="DEBUG", action="store_true", default=False, help="Turn on some debug messages")
    op.add_option("-q", "--quiet", dest="QUIET", action="store_true", default=False, help="Turn off messages and plotting")
    op.add_option("-p", "--plottoy", dest="PLOTTOY", action="store_true", default=False, help="Plot the toy definition (default: %default)")
    op.add_option("--plotprefix", dest="PLOTPREFIX", default="toy6", help="Plot prefix (default: %default)")
    op.add_option("--limits", dest="LIMITS", default=None, help="Text file with parameter limits (default: %default)")
    op.add_option("-n", dest="NSAMPLES", type=int, default=1000, help="Number of samples (default: %default)")
    op.add_option("-b", dest="NBINS", type=int, default=20, help="Number of bins (default: %default)")
    op.add_option("-s", dest="NSIGNAL", type=int, default=20, help="Number of signals to sample for parameterisation (default: %default)")
    op.add_option("-c", dest="CORRMODE", default="sane", help="Correlation mode --- none | sane | mad (default: %default)")
    op.add_option("-o", dest="OUT", default="phi2.json", help="Output file for stats (default: %default)")
    op.add_option("-t", dest="TARGET", default=95, type=float, help="G.o.F target percentile (default: %default)")
    op.add_option("--seed", dest="SEED", type=int, default=12345, help="Random seed (default: %default)")
    op.add_option("--multistart", dest="NSTART", type=int, default=100, help="Number of points to sample to find startpoint (default: %default)")
    op.add_option("-w", dest="WEIGHTS", default=None, help="Obervable file (default: %default)")
    op.add_option("-d", dest="DATA", default=None, help="Data file to compare to (default: %default)")
    opts, args = op.parse_args()

    if opts.WEIGHTS is None:
        raise Exception("No weight file spefified -- use  -w on CL")
    if opts.DATA is None:
        raise Exception("No data file spefified -- use  -d on CL")



    IO = app.tools.TuningObjective(opts.WEIGHTS, opts.DATA, args[0], debug=opts.DEBUG, limits=opts.LIMITS)
    yvals = IO._Y
    yerrs = IO._E


    rank=0
    size=1
    try:
        from mpi4py import MPI
        comm = MPI.COMM_WORLD
        size = comm.Get_size()
        rank = comm.Get_rank()
    except Exception as e:
        print("Exception when trying to import mpi4py:", e)
        pass

    # Distribute the bins (objects or whatever you want to call them) amongst the available ranks
    if rank==0:
        import time
        np.random.seed(opts.SEED)

        C = app.tools.mkCov(yerrs)
        # We need to occasionally deal with 
        #      ValueError: the input matrix must be positive semidefinite
        # https://stackoverflow.com/questions/41515522/numpy-positive-semi-definite-warning
        min_eig = np.min(np.real(np.linalg.eigvals(C)))
        if min_eig < 0:
            C -= 10*min_eig * np.eye(*C.shape)

        import scipy.stats as st
        # Get a once smeared sample to be used as toy data # NOTE this requires a factor two in phi2 later
        # _yvals=np.ones(opts.NBINS)*-1
        # #while any([y<0 for y in _yvals]):
        # _yvals =  st.multivariate_normal(yvals, C).rvs(size=1)
        # yvals=_yvals
        # yerrs = np.array([np.sqrt(abs(y)) for y in yvals])
        # Also get the sample covariance matrix based on the sample errors
        # C = mkCov(yerrs, opts.CORRMODE)
        min_eig = np.min(np.real(np.linalg.eigvals(C)))
        if min_eig < 0:
            C -= 10*min_eig * np.eye(*C.shape)


        # Here we draw samples using the Covariance matrix above
        mn = st.multivariate_normal(yvals, C)
        sampledyvals = mn.rvs(size=opts.NSAMPLES)

        # This is the covariance matrix without correlations and WITHOUT the additional factor of sqrt(2)
        Cinv =  np.linalg.inv(C)
        Cinvchi2 = np.diag([1./(e**2) for e in yerrs])

        def chi2(datavals, modelvals, ivariance):
            deltas = np.atleast_2d(datavals - modelvals)
            c2 = deltas.dot(ivariance).dot(deltas.T)
            return c2[0,0]

        c2s_naive = np.empty([opts.NSAMPLES,1])
        for i in range(opts.NSAMPLES):
            c2s_naive[i] = chi2(yvals, sampledyvals[i], Cinvchi2)

        c2s_full = np.empty([opts.NSAMPLES,1])
        for i in range(opts.NSAMPLES):
            c2s_full[i] = chi2(yvals, sampledyvals[i], Cinv)

        # This is the covariance matrix without correlations but WITH that extra factor of sqrt(2) --- to be used when doing the
        # bootstrapping
        Cinvtrivial = np.diag([1./(2*e**2) for e in yerrs])
        # Cinvtrivial = np.diag([1./(np.sqrt(2)*e**2) for e in yerrs])

        allJobs=terr.tools.chunkIt(range(opts.NSAMPLES), size) # A list of lists of approximately the same length

    else:
        R = None
        sampledyvals = None
        allJobs = []
        Cinvtrivial = None
        xmids=None



    # Scatter and broadcast operations
    comm.Barrier()
    rankJobs = comm.scatter(allJobs, root=0)
    # R = comm.bcast(R, root=0)
    Cinvtrivial = comm.bcast(Cinvtrivial, root=0)
    sampledyvals = comm.bcast(sampledyvals, root=0)
    comm.Barrier()


    # This is the bootstrapping
    restrivial = []
    minPhi2 = 1e11
    minP=[]
    allP=[]
    from scipy import optimize
    for num, sv in enumerate(sampledyvals[rankJobs]):
        # TODO add multistart or similar
        IO._Y=sv
        minres=IO.minimize(opts.NSTART)
        # minres=optimize.minimize(lambda x:chi2wCov(sv, xmids, Cinvtrivial,x), center, bounds=box)
        restrivial.append(minres["fun"])
        allP.append(minres["x"])
        if minres["fun"] < minPhi2:
            minPhi2 = minres["fun"]
            minP = minres["x"]
        if num%100 == 0 and rank==0:
            print("[{}] Done with {}/{}".format(rank, num, len(rankJobs)))
            sys.stdout.flush()

    comm.Barrier()

    # Collective operation --- gather all information on rank 0 for plotting etc.
    outputtrivial = comm.gather(restrivial, root=0)
    allminPhi2    = comm.gather(minPhi2, root=0)
    allminP       = comm.gather(minP, root=0)
    allallP       = comm.gather(allP, root=0)

    if rank==0:
        ALL = [item for sublist in outputtrivial for item in sublist]
        ALLP = np.array([item for sublist in allallP for item in sublist])

        # Sample covariance in param space and ET construction
        # COV_sample     = np.cov(np.array(ALLP).T)
        # COV_sample_inv = np.linalg.inv(COV_sample)
        ET, CTR = terr.ellipsis.construct(ALLP, plot_prefix=opts.PLOTPREFIX, percentile=float(opts.TARGET))


        # from IPython import embed
        # embed()
        from matplotlib import pyplot as plt
        import matplotlib as mpl
        PTS=ALLP
        for i, px in enumerate(IO._SCLR.pnames):
            for j, py in enumerate(IO._SCLR.pnames):
                if i!= j:
                    plt.clf()
                    plt.style.use('ggplot')
                    fig,ax = plt.subplots(1)
                    ax.set_aspect('equal')
                    ax.scatter(PTS[:,i],  PTS[:,j],  c="b", marker=".")
                    ax.scatter(ET[:,i], ET[:,j], c="r", marker="x", s=100)
                    ax.scatter(CTR[i], CTR[j], c="magenta", marker="*", s=100)
                    plt.xlabel(px)
                    plt.ylabel(py)
                    plt.savefig("{}_ellipsis_{}_{}.pdf".format(opts.PLOTPREFIX, i, j))





        winner  = allminPhi2.index(min(allminPhi2))
        winnerP = allminP[winner]


        # This is the tuning main minimisation --- note that this uses the covariance WITHOUT sqrt(2)
        Cinv_phi2 = np.diag([1./e**2 for e in yerrs])

        # Note add multistart here
        # MIN_tune = optimize.minimize(lambda x:chi2wCov(yvals, xmids, Cinv_phi2, x), center, bounds=box)
        IO_tune = app.tools.TuningObjective(opts.WEIGHTS, opts.DATA, args[0], debug=opts.DEBUG)
        MIN_tune = IO_tune.minimize(opts.NSTART)
        Cinv_tune=MIN_tune["hess_inv"].todense()

        jd = {
                "CORRMODE"   : opts.CORRMODE,
                "NBINS"      : len(yvals),
                "NDF"        : opts.NBINS-2, # TODO eventually nparams
                "TUNECHI2"   : MIN_tune["fun"],
                "TUNEPARS"   : list(MIN_tune["x"].ravel()),
                "PNAMES"     : IO._SCLR.pnames,
                "ET" : ET.tolist(),
                "YVALS": IO_tune._Y.tolist(),
                "WINNERPARS"   : list(winnerP),
                "WINNERPHI2"   : min(allminPhi2),
                "TUNEINVDATACOV" : list(Cinv_phi2.ravel()),
                "TUNEINVPARAMCOV" : list(Cinv_tune.ravel()),
                "VCHI2NAIVE" : list(c2s_naive.ravel()),
                "VCHI2FULL"  : list(c2s_full.ravel()),
                "VPHI2": list(ALL),
                }

        import json
        with open(opts.OUT, "w") as f:
            json.dump(jd, f, indent=4)
        oo = MIN_tune["x"]

        xmids = [x for x in range(len(yvals))]

        plotEigenTuneHistos(IO, jd, xmids, oo, ET, plot_prefix=opts.PLOTPREFIX)
